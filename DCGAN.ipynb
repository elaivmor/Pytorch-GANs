{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmGmRbShswhOTH2FtpEnWf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eliavmor/Pytorch-GANs/blob/master/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI7-TOpHfsZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os\n",
        "import os.path as path\n",
        "drive.mount(\"/content/drive\")\n",
        "drive_path = \"/content/drive/My Drive/Colab Notebooks\"\n",
        "checkpoint_path = os.path.join(drive_path, \"checkpoint\")\n",
        "output_path = os.path.join(drive_path, \"output_images\")\n",
        "if not path.isdir(checkpoint_path):\n",
        "    os.mkdir(checkpoint_path)\n",
        "if not path.isdir(output_path):\n",
        "    os.mkdir(output_path)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fUD5VscFqxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.linear_process = nn.Sequential(\n",
        "            nn.Linear(100, 128 * 2 * 2)\n",
        "        )\n",
        "        self.post_linear_process = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 128, 3),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "\n",
        "            nn.Upsample(scale_factor=2),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 3),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 32, 3),\n",
        "            nn.BatchNorm2d(32, 0.8),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "\n",
        "            nn.Upsample(scale_factor=2),\n",
        "\n",
        "            nn.ConvTranspose2d(32, 1, 5),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    \n",
        "    def forward(self, noise):\n",
        "        x = self.linear_process(noise)\n",
        "        x = x.view(-1, 128, 2, 2)\n",
        "        fake_images = self.post_linear_process(x)\n",
        "        return fake_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9EOCBIuKexE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.step1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, 5),\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(p=0.25),\n",
        "            nn.Conv2d(6, 8, 5),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(p=0.25),\n",
        "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(p=0.25),\n",
        "            nn.Conv2d(16, 4, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(4),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(p=0.25),\n",
        "        )\n",
        "        self.step2 = nn.Sequential(\n",
        "            nn.Linear(4*5*5, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, images):\n",
        "        x = self.step1(images)\n",
        "        x = x.view(-1, 4*5*5)\n",
        "        predictions = self.step2(x)\n",
        "        return predictions\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPROMxYDi6Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# init weights for conv layers and BatchNorm2D\n",
        "def init_weights(layer):\n",
        "    if isinstance(layer, nn.ConvTranspose2d):\n",
        "        layer.weight.data.normal_(0, 0.02)\n",
        "    elif isinstance(layer, nn.BatchNorm2d):\n",
        "        layer.weight.data.normal_(1, 0.02)\n",
        "        layer.bias.data.fill_(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04v9TU8fKqbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(fake_images, output_path):\n",
        "    plt.figure(figsize=(15,15))\n",
        "    for i in range(16):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(fake_images[i, 0, :, :].detach().cpu(), cmap=\"gray\")\n",
        "    plt.savefig(output_path)\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3jPLAfLKxT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "D = Discriminator()\n",
        "G = Generator()\n",
        "\n",
        "D.apply(init_weights)\n",
        "# G.apply(init_weights)\n",
        "\n",
        "run_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if run_gpu else \"cpu\")\n",
        "\n",
        "G.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/checkpoint/mnist_generator_180.pth'))\n",
        "G = G.to(device)\n",
        "D = D.to(device)\n",
        "\n",
        "d_optimizer = Adam(params=D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "g_optimizer = Adam(params=G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "test_fake = torch.rand(17 * 100)\n",
        "test_fake = test_fake.view(-1, 100).to(device)\n",
        "\n",
        "data = torchvision.datasets.MNIST(root=\"./data\", transform=transforms.Compose(\n",
        "            [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
        "        ), download=True)\n",
        "\n",
        "datal = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    D_real_err = []\n",
        "    D_fake_err = []\n",
        "    G_err = []\n",
        "    for idx, batch in enumerate(datal):\n",
        "        images = batch[0]\n",
        "        batch_size = images.size()[0]\n",
        "        # =======   Train Discriminator    ==========\n",
        "        d_optimizer.zero_grad()\n",
        "        # move images to device\n",
        "        images = images.to(device)\n",
        "        # predict real images\n",
        "        d_real_prediction = D(images)\n",
        "        \n",
        "        # create real an fake labels for the given batch_size\n",
        "        real_labels = torch.ones(batch_size).view(-1, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size).view(-1, 1).to(device)\n",
        "        \n",
        "        # calculate real images error\n",
        "        real_err = criterion(d_real_prediction, real_labels)\n",
        "\n",
        "        # create random noise batch\n",
        "        noise = torch.randn(batch_size * 100).view(-1, 100).to(device)\n",
        "\n",
        "        # generate fake images\n",
        "        fake_images = G(noise)\n",
        "        \n",
        "        # get discriminator answer\n",
        "        # use detach() on fake images in order to prevent Generator training\n",
        "        d_fake_prediction = D(fake_images.detach())\n",
        "\n",
        "        fake_err = criterion(d_fake_prediction, fake_labels)\n",
        "        err_d = (fake_err + real_err) / 2\n",
        "        err_d.backward()\n",
        "        d_optimizer.step()\n",
        "        # =======   End Train Discriminator    ==========\n",
        "\n",
        "        # =======   Train Generator   ==========\n",
        "        g_optimizer.zero_grad()\n",
        "        fake_images = G(noise)\n",
        "        d_fake_prediction = D(fake_images.to(device))\n",
        "        g_fake_err = criterion(d_fake_prediction, real_labels)\n",
        "        g_fake_err.backward()\n",
        "        g_optimizer.step()\n",
        "        # =======   End Train Generator    ==========\n",
        "    if not (epoch % 10):\n",
        "        print(\"Epoch [{}/{}]\".format(epoch, epochs))\n",
        "        print(\"D real Error {:.4f}\".format(np.average(D_real_err)))\n",
        "        print(\"D fake Error {:.4f}\".format(np.average(D_fake_err)))\n",
        "        print(\"G Error {:.4f}\".format(np.average(G_err)))\n",
        "        with torch.no_grad():\n",
        "            save_images(G(test_fake), \"/content/drive/My Drive/Colab Notebooks/output_images/mnist_generator_{}.jpg\".format(epoch + 180))\n",
        "        with open('/content/drive/My Drive/Colab Notebooks/checkpoint/mnist_discriminator_{}.pth'.format(epoch), 'wb') as f:\n",
        "            torch.save(D.state_dict(), f)\n",
        "        with open('/content/drive/My Drive/Colab Notebooks/checkpoint/mnist_generator_{}.pth'.format(epoch + 180), 'wb') as f:\n",
        "            torch.save(G.state_dict(), f)\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiQI4QfQYsBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "def create_animation(images_path):\n",
        "    ims_path = [os.path.join(images_path, f) for f in os.listdir(images_path) if f.endswith('.jpg')]\n",
        "    images = []\n",
        "    with imageio.get_writer(os.path.join(images_path, \"gan_result.gif\"), mode='I', duration=0.2) as writer:\n",
        "        for filename in ims_path:\n",
        "            image = imageio.imread(filename)\n",
        "            writer.append_data(image)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}